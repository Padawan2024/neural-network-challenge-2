{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alIIEHibGc3M"
      },
      "source": [
        "## Part 1: Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "6eDUJ4NtGc3P",
        "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#  Import and read the attrition data\n",
        "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
        "attrition_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g22aQSY4Gc3Q",
        "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
      },
      "outputs": [],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "attrition_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50vMgBEnJbfM"
      },
      "outputs": [],
      "source": [
        "# Create y_df with the Attrition and Department columns\n",
        "y_df = attrition_df[['Attrition', 'Department']]\n",
        "y_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Virka0zLGc3R",
        "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
      },
      "outputs": [],
      "source": [
        "# Create a list of at least 10 column names to use as X data\n",
        "x = ['Education', 'Age', 'DistanceFromHome', 'JobSatisfaction', 'OverTime', 'StockOptionLevel', 'WorkLifeBalance', 'YearsAtCompany', 'YearsSinceLastPromotion', 'NumCompaniesWorked'] \n",
        "\n",
        "# Create X_df using your selected columns\n",
        "X_df = attrition_df[x]\n",
        "\n",
        "# Show the data types for X_df\n",
        "X_df.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KaJfdOGUMHMR"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYubUJqiLCSp",
        "outputId": "53f31721-571c-4c94-d13e-25a715749593"
      },
      "outputs": [],
      "source": [
        "# Convert your X data to numeric data types however you see fit\n",
        "# Add new code cells as necessary\n",
        "\n",
        "train_overtime = X_train['OverTime']\n",
        "test_overtime = X_test['OverTime']\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_overtime_encoded = le.fit_transform(train_overtime)\n",
        "test_overtime_encoded = le.transform(test_overtime)\n",
        "\n",
        "X_train['OverTime'] = train_overtime_encoded\n",
        "X_test['OverTime'] = test_overtime_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWA-aIA5Gc3T"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler to the training data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Scale the training and testing data\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z0Mky8vQSz4",
        "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder for the Department column\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "ohe.fit(y_train[['Department']])\n",
        "\n",
        "# Create two new variables by applying the encoder\n",
        "# to the training and testing data\n",
        "y_train_dep_encoded = ohe.transform(y_train[['Department']]).toarray()\n",
        "y_test_dep_encoded = ohe.transform(y_test[['Department']]).toarray()\n",
        "y_train_dep_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G4DSpvFRrk4",
        "outputId": "9842e948-8a55-4b80-8fac-f96714e85589"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder for the Attrition column\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "ohe.fit(y_train[['Attrition']])\n",
        "\n",
        "# Create two new variables by applying the encoder\n",
        "# to the training and testing data\n",
        "y_train_attr_encoded = ohe.transform(y_train[['Attrition']]).toarray()\n",
        "y_test_attr_encoded = ohe.transform(y_test[['Attrition']]).toarray()\n",
        "y_train_attr_encoded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykNmu_WWGc3T"
      },
      "source": [
        "## Create, Compile, and Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WUptZqmSGc3T"
      },
      "outputs": [],
      "source": [
        "# Find the number of columns in the X training data\n",
        "X_column_length = X_train.shape[1]\n",
        "\n",
        "# Create the input layer\n",
        "input_layer = layers.Input(shape=(X_column_length,), name='input_features')\n",
        "\n",
        "# Create at least two shared layers\n",
        "shared_layer1 = layers.Dense(64, activation='relu', name='shared1')(input_layer)\n",
        "shared_layer2 = layers.Dense(128, activation='relu', name='shared2')(shared_layer1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JukjTm2yTEqd"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Department\n",
        "# with a hidden layer and an output layer\n",
        "\n",
        "# Create the hidden layer\n",
        "dep_hidden_layer = layers.Dense(32, activation='relu', name='department_hidden')(shared_layer2)\n",
        "\n",
        "# Create the output layer\n",
        "department_output = layers.Dense(3, activation='softmax', name='department_output')(dep_hidden_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9OqhUiOJUBkR"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Attrition\n",
        "# with a hidden layer and an output layer\n",
        "\n",
        "# Create the hidden layer\n",
        "attr_hidden_layer = layers.Dense(32, activation='relu', name='attrition_hidden')(shared_layer2)\n",
        "\n",
        "# Create the output layer\n",
        "attrition_output = layers.Dense(2, activation='sigmoid', name = 'attrition_output')(attr_hidden_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twmuejdxGc3T",
        "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[department_output, attrition_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'department_output': 'categorical_crossentropy',\n",
        "                    'attrition_output': 'binary_crossentropy'},\n",
        "              metrics={'department_output':'accuracy',\n",
        "                       'attrition_output':'accuracy'}\n",
        "                    )\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8oGy0dpGc3U",
        "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(X_train_scaled,\n",
        "          {'department_output':y_train_dep_encoded, 'attrition_output': y_train_attr_encoded},\n",
        "          epochs=100,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2\n",
        "          )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsMoaQlgGc3U",
        "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model with the testing data\n",
        "test_results = model.evaluate(X_test_scaled,\n",
        "                              {'department_output':y_test_dep_encoded, 'attrition_output': y_test_attr_encoded})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlCtlHi0Vt54",
        "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
      },
      "outputs": [],
      "source": [
        "# Print the accuracy for both department and attrition\n",
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attrition_df['Attrition'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attrition_df['Department'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGSyfsZfWOQM"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In the provided space below, briefly answer the following questions.\n",
        "\n",
        "1. Is accuracy the best metric to use on this data? Why or why not?\n",
        "\n",
        "2. What activation functions did you choose for your output layers, and why?\n",
        "\n",
        "3. Can you name a few ways that this model might be improved?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9SLpFnWvbF"
      },
      "source": [
        "YOUR ANSWERS HERE\n",
        "\n",
        "1. Accuracy may not be the best metric for evaluating models predicting employee attrition and departmental fit due to potential class imbalance, where a model could achieve high accuracy by predicting the majority class. Additionally, a false negative in attrition prediction (failing to predict that an employee will leave) could have more serious consequences than a false positive (predicting that an employee will leave when they do not). \n",
        "According to the Xpert Learning Assistant, metrics like precision, recall, F1-score, and AUC-ROC can provide more valuable insights, especially in imbalanced datasets. Recall measures how well the model identifies employees likely to leave, while precision assesses the accuracy of those predictions. AUC-ROC evaluates the model's performance across different thresholds, considering both true and false positives.\n",
        "\n",
        "2. For employee attrition prediction, I used the sigmoid activation function as it is a binary classification task, which outputs a probability between 0 and 1 for whether an employee will leave or stay. For department prediction, I used the softmax activation function as it is a multi-class classification task, which outputs a probability distribution across multiple departments, with the highest probability indicating the best fit for the employee.\n",
        "\n",
        "3. Changing the loss function for each output to account for the imbalanced data. Get more data to balance the counts for the classes in attrition and departments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
